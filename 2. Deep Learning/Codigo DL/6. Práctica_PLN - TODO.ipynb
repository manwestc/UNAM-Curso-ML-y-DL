{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"#113D68\" size=6>Deep Learning con Python y Keras</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=5>Parte 6. Redes Neuronales Recurrentes</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=4>6. Práctica: Procesamiento del Lenguaje Natural</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#113D68\" size=3>Manuel Castillo Cara</font><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Licencia</font></h2>\n",
    "\n",
    "<p><small><small>Copyright 2022 Manuel Castillo Cara.</p>\n",
    "<p><small><small> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at </p>\n",
    "<p><small><small> <a href=\"https://www.apache.org/licenses/LICENSE-2.0\">https://www.apache.org/licenses/LICENSE-2.0</a> </p>\n",
    "<p><small><small> Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. </p>\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "* [0. Contexto](#section0)\n",
    "* [1. Descripción del problema: generación de texto](#section1)\n",
    "* [2. LSTM de linea base](#section2)\n",
    "    * [2.1. Cargar el dataset](#section2.1)\n",
    "    * [2.2. Conversión a numérico](#section2.2)\n",
    "    * [2.3. Dimensiones del dataset](#section2.3)\n",
    "    * [2.4. Procesamiento de datos](#section2.4)\n",
    "    * [2.5. Diseño de la LSTM](#section2.5)\n",
    "    * [2.6. Crear puntos de control](#section2.6)\n",
    "    * [2.7. Resultados](#section2.7)\n",
    "* [3. Generación de texto con LSTM](#section3)\n",
    "    * [3.1. Cargar los pesos de LSTM](#section3.1)\n",
    "    * [3.2. Convertir de entero a carácter](#section3.2)\n",
    "    * [3.3. Resultados y evaluación](#section3.3)\n",
    "* [4. LSTM más profunda](#section4)\n",
    "* [5. Mejorar nuestro modelo](#section5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 0. Contexto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto, aprenderemos a crear un modelo generativo de texto utilizando LSTM:\n",
    "* Descripción de un modelos generativos de texto.\n",
    "* Enmarcar el problema de las secuencias de texto a un modelo generativo.\n",
    "* Desarrollar una LSTM para generar secuencias de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\" size=6>1. Descripción del problema: generación de texto</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAmos a trabajar el libro de \"Alicia en el país de las maravillas\", por lo que podemos descargarlo de la página (Texto sin formato UTF-8) de este libro de forma gratuita y colocarlo en su directorio de trabajo con el nombre `wonderland.txt`. \n",
    "\n",
    "Abrimos el archivo y eliminamos el encabezado:\n",
    "```\n",
    "        *** START OF THIS PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND ***\n",
    "```\n",
    "\n",
    "El pie de página es todo el texto después de la línea de texto que dice:\n",
    "```\n",
    "        THE END\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Más información sobre el [Proyecto Gutenberg](https://www.gutenberg.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Descargar el libro [Alice's Adventures in Wonderland](https://www.gutenberg.org/ebooks/11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\" size=6>2. LSTM de linea base</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección desarrollaremos una red LSTM simple para aprender secuencias de caracteres de Alicia en el país de las maravillas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2.1\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.1. Cargar el dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos importando las clases y funciones que pretendemos usar para entrenar nuestro modelo.\n",
    "\n",
    "Debemos cargar el texto ASCII y convertir todos los caracteres a minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small LSTM Network to Generate Text for Alice in Wonderland\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# load ascii text and covert to lowercase\n",
    "filename = \"data/wonderland.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2.2\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.2. Conversión a numérico</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No podemos modelar los caracteres directamente, sino que debemos convertir los caracteres a números enteros. \n",
    "\n",
    "Por ejemplo, la lista de caracteres en minúscula ordenados únicos en el libro es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '#': 4,\n",
       " '$': 5,\n",
       " '%': 6,\n",
       " \"'\": 7,\n",
       " '(': 8,\n",
       " ')': 9,\n",
       " '*': 10,\n",
       " ',': 11,\n",
       " '-': 12,\n",
       " '.': 13,\n",
       " '/': 14,\n",
       " '0': 15,\n",
       " '1': 16,\n",
       " '2': 17,\n",
       " '3': 18,\n",
       " '4': 19,\n",
       " '5': 20,\n",
       " '6': 21,\n",
       " '7': 22,\n",
       " '8': 23,\n",
       " '9': 24,\n",
       " ':': 25,\n",
       " ';': 26,\n",
       " '?': 27,\n",
       " '@': 28,\n",
       " '[': 29,\n",
       " ']': 30,\n",
       " '_': 31,\n",
       " 'a': 32,\n",
       " 'b': 33,\n",
       " 'c': 34,\n",
       " 'd': 35,\n",
       " 'e': 36,\n",
       " 'f': 37,\n",
       " 'g': 38,\n",
       " 'h': 39,\n",
       " 'i': 40,\n",
       " 'j': 41,\n",
       " 'k': 42,\n",
       " 'l': 43,\n",
       " 'm': 44,\n",
       " 'n': 45,\n",
       " 'o': 46,\n",
       " 'p': 47,\n",
       " 'q': 48,\n",
       " 'r': 49,\n",
       " 's': 50,\n",
       " 't': 51,\n",
       " 'u': 52,\n",
       " 'v': 53,\n",
       " 'w': 54,\n",
       " 'x': 55,\n",
       " 'y': 56,\n",
       " 'z': 57,\n",
       " 'ù': 58,\n",
       " '—': 59,\n",
       " '‘': 60,\n",
       " '’': 61,\n",
       " '“': 62,\n",
       " '”': 63,\n",
       " '\\ufeff': 64}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "char_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2.3\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.3. Dimensiones del dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que se cargó el libro y se preparó el mapeo, podemos resumir el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  164202\n",
      "Total Vocab:  65\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "# summarize the loaded data\n",
    "n_chars = ???\n",
    "n_vocab = ???\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este tutorial, dividiremos el texto del libro en subsecuencias con una longitud fija de 100 caracteres, una longitud arbitraria. \n",
    "\n",
    "Cada patrón de entrenamiento de la red se compone de 100 pasos de tiempo de un carácter (X) seguidos de una salida de carácter (y). \n",
    "\n",
    "Por ejemplo, si la longitud de la secuencia es 5 (para simplificar), los dos primeros patrones de entrenamiento serían los siguientes:\n",
    "```\n",
    "            CHAPT -> E\n",
    "            HAPTE -> R\n",
    "```\n",
    "A medida que dividimos el libro en estas secuencias, convertimos los caracteres a números enteros usando nuestra tabla de búsqueda que preparamos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  164102\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que se han dividio en secuencias de 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdataX\u001b[49m[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataX' is not defined"
     ]
    }
   ],
   "source": [
    "# Secuencia 0\n",
    "dataX[0]\n",
    "# Total Secuencia 0\n",
    "len(dataX[0])\n",
    "# Para esa secuencia de X le correspondería la salida\n",
    "dataY[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2.4\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.4. Procesamiento de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos preparado nuestros datos de entrenamiento, necesitamos transformarlos. \n",
    "1. Transformar la lista de secuencias de entrada en la forma ***[muestras, pasos de tiempo, características].***\n",
    "2. Cambiar la escala de los números enteros al rango de 0 a 1 (normalización) y usar la función de activación sigmoidea.\n",
    "3. Convertir los patrones de salida (caracteres individuales convertidos en enteros) con One-Hot Encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "??? \n",
    "print(X[0])\n",
    "print(X[0][0])\n",
    "print(X[0][0[0]])\n",
    "# normalize\n",
    "??? \n",
    "\n",
    "# one hot encode the output variable\n",
    "??? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2.5\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.5. Diseño de la LSTM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos definir nuestro modelo LSTM. \n",
    "1. Definimos una única capa LSTM oculta con 256 unidades de memoria. \n",
    "2. La red utiliza un Dropout del 20%. \n",
    "3. La capa de salida es una capa densa que utiliza la función de activación Softmax. \n",
    "4. Compilación con pérdida logarítmica (`categorical_crossentropy`)\n",
    "5. Usaremos el algoritmo de optimización de Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "??? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2.6\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.6. Crear puntos de control</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el mejor conjunto de pesos (menor pérdida) para instanciar nuestro modelo generativo en la siguiente sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2.7\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.7. Resultados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos un número modesto de 20 épocas y un gran tamaño de batch de 128 patrones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1283/1283 [==============================] - ETA: 0s - loss: 3.0190\n",
      "Epoch 00001: loss improved from inf to 3.01901, saving model to weights-improvement-01-3.0190.hdf5\n",
      "1283/1283 [==============================] - 301s 235ms/step - loss: 3.0190\n",
      "Epoch 2/20\n",
      "1283/1283 [==============================] - ETA: 0s - loss: 2.8445\n",
      "Epoch 00002: loss improved from 3.01901 to 2.84446, saving model to weights-improvement-02-2.8445.hdf5\n",
      "1283/1283 [==============================] - 297s 231ms/step - loss: 2.8445\n",
      "Epoch 3/20\n",
      "1283/1283 [==============================] - ETA: 0s - loss: 2.7635\n",
      "Epoch 00003: loss improved from 2.84446 to 2.76349, saving model to weights-improvement-03-2.7635.hdf5\n",
      "1283/1283 [==============================] - 299s 233ms/step - loss: 2.7635\n",
      "Epoch 4/20\n",
      "1033/1283 [=======================>......] - ETA: 56s - loss: 2.7060"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "??? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\" size=6>3. Generación de texto con LSTM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La generación de texto utilizando la red LSTM entrenada es relativamente sencilla. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3.1\"></a>\n",
    "# <font color=\"#004D7F\" size=5>3.1. Cargar los pesos de LSTM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, cargamos los datos y definimos la red exactamente de la misma manera\n",
    "\n",
    "Los pesos de la red se cargan desde un archivo de punto de control y no es necesario entrenar la red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-19-1.9435.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3.2\"></a>\n",
    "# <font color=\"#004D7F\" size=5>3.2. Convertir de entero a carácter</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un mapeo inverso que podamos usar para convertir los números enteros de nuevo en caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the loaded data\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3.3\"></a>\n",
    "# <font color=\"#004D7F\" size=5>3.3. Resultados y evaluación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, necesitamos realmente hacer predicciones de manera que:\n",
    "1. Comenzamos primero con una semilla como entrada\n",
    "2. Generamos el siguiente carácter y \n",
    "3. Actualizamos la semilla para agregar el carácter generado al final y recortar el primer carácter. \n",
    "\n",
    "Este proceso se repite mientras queramos predecir nuevos caracteres (por ejemplo, una secuencia de 1000 caracteres de longitud). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar algunas observaciones sobre el texto generado.\n",
    "* Generalmente se ajusta al formato de línea observado en el texto original de menos de 80 caracteres.\n",
    "* Los caracteres están separados en grupos parecidos a palabras y la mayoría de los grupos son palabras reales en inglés (por ejemplo, _the, little_ y _was),_ pero muchos no (por ejemplo, _lott, tiie_ y _taede)._\n",
    "* Algunas de las palabras en secuencia tienen sentido (por ejemplo, y el _white rabbit),_ pero otras muchas no (por ejemplo, _wese tilel)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\" size=6>4. LSTM más profunda</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos intentar mejorar la calidad del texto generado creando una red mucho más profunda.\n",
    "\n",
    "1. Definimos una única capa LSTM oculta con 256 unidades de memoria. \n",
    "2. La red utiliza un Dropout del 20%. \n",
    "3. Una capa LSTM de 256 unidades.\n",
    "4. Otra capa Dropout del 20%. \n",
    "4. La capa de salida es una capa densa que utiliza la función de activación Softmax. \n",
    "4. Compilación con pérdida logarítmica (`categorical_crossentropy`)\n",
    "5. Usaremos el algoritmo de optimización de Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "??? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También cambiaremos el nombre de archivo de los pesos con puntos de control para que podamos distinguir entre los pesos de esta red y la anterior (agregando la palabra más grande en el nombre del archivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "??? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, aumentaremos el número de épocas de entrenamiento de 20 a 50 y disminuiremos el tamaño del lote de 128 a 64 para darle a la red más oportunidades de actualizarse y aprender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "??? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en la sección anterior, podemos usar este mejor modelo de la ejecución para generar texto. \n",
    "\n",
    "El único cambio que debemos realizar es la especificación de la topología de la red y desde qué archivo se van a generar los pesos de la red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"???\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\" size=6>5. Mejorar nuestro modelo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se muestra una muestra de ideas que tal vez desee investigar para mejorar aún más el modelo:\n",
    "* Predecir menos de 1000 caracteres como salida para una semilla determinada.\n",
    "* Eliminar toda la puntuación del texto fuente y, por tanto, del vocabulario de los modelos.\n",
    "* Pruebe un One-Hot Encoding para las secuencias de entrada.\n",
    "* Entrene al modelo en oraciones rellenas en lugar de secuencias aleatorias de caracteres.\n",
    "* Aumentar el número de épocas de entrenamiento a 100 o más.\n",
    "* Agregue Dropout a la capa de entrada visible y considere ajustar el porcentaje de Dropout.\n",
    "* Ajuste el tamaño de batch, pruebe con un tamaño de batch de 1 como línea de base (muy lenta) y tamaños más grandes a partir de ahí.\n",
    "* Agregue más unidades de memoria a las capas y / o más capas.\n",
    "* Cambie las capas de LSTM para que tengan estado para mantener el estado en todos los batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
