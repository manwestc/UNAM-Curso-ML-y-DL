{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=6>Módulo 7. Proyectos de Machine Learning</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=5>3. Proyecto de Regresión</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Machine Learning con Python</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "<a id=\"indice\"></a>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "    * [1.1. Importar librerías](#section11)\n",
    "    * [2.1. Cargar el dataset](#section12)\n",
    "* [2. Estadística descriptiva](#section2)\n",
    "    * [2.1. Dimensiones del dataset](#section21)\n",
    "    * [2.2. Visualización de datos](#section22)\n",
    "    * [2.3. Resumen estadístico](#section23)\n",
    "    * [2.4. Tipo de datos](#section24)\n",
    "    * [2.5. Correlación entre atributos](#section25)\n",
    "    * [2.6. Valores NaN](#section26)\n",
    "* [3. Visualización del dataset](#section3)\n",
    "    * [3.1. Gráficos Univariado](#section31)\n",
    "    * [3.2. Gráficos multivariados](#section32)\n",
    "    * [3.3. Resumen de ideas](#section33)\n",
    "* [4. Fase de modelado](#section4)\n",
    "    * [4.1. Crear conjunto de validación](#section41)\n",
    "    * [4.2. Evaluación de línea base](#section42)\n",
    "    * [4.3. Evaluar modelos: estandarización](#section43)\n",
    "* [5. Fase de Optimización](#section5)\n",
    "    * [5.1. Optimización de k-NN](#section51)\n",
    "* [6. Agoritmos ensamblados](#section6)\n",
    "    * [6.1. Comparar algoritmos ensamblados](#section61)\n",
    "    * [6.2. Fase de optimización GBM](#section62)\n",
    "* [7. Fase de forecasting](#section7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Introducción</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este proyecto, trabajaremos el conjunto de datos _Boston House Price._ Cada registro en la base de datos describe un suburbio de la ciudad de Boston. Los datos se extrajeron del área estadística metropolitana estándar de Boston (SMSA) en 1970. Los atributos se definen de la siguiente manera:\n",
    "* CRIM: tasa de criminalidad per cápita por ciudad.\n",
    "* ZN: proporción de tierra residencial zonificada para lotes de más de 25000 pies cuadrados.\n",
    "* INDUS: proporción de acres de negocios no minoristas por ciudad.\n",
    "* CHAS: variable ficticia del río Charles (=1 si el trecho delimita el río; 0 de lo contrario).\n",
    "* NOX: concentración de óxidos nítricos (partes por 10 millones).\n",
    "* RM: número medio de habitaciones por vivienda.\n",
    "* AGE: proporción de unidades ocupadas por el propietario construidas antes de 1940.\n",
    "* DIS: distancias ponderadas a cinco centros de empleo de Boston.\n",
    "* RAD: índice de accesibilidad a autopistas radiales.\n",
    "* TAX: tasa de impuesto a la propiedad de valor total por USD10000. \n",
    "* PTRATIO: proporción alumno-profesor por ciudad.\n",
    "* B: $1000(Bk - 0.63)^2$ donde Bk es la proporción de personas de color por ciudad\n",
    "* LSTAT: % menor estado de la población.\n",
    "* MEDV: valor medio de las viviendas ocupadas por sus propietarios en USD1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "## <font color=\"#004D7F\"> 1.1. Importar librerías</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, importemos todos los módulos, funciones y objetos que vamos a utilizar en este tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Project: Sonar rocks or mines\n",
    "\n",
    "# Load libraries\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Load sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 1.2. Cargar el dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos de _Boston Housing Price._ Puede ver que estamos especificando los nombres cortos para cada atributo para que podamos referenciarlos claramente más adelante. También puede ver que los atributos están delimitados por espacios en blanco en lugar de comas en este archivo e indicamos esto a la función `read_csv()` a través del argumento `delim.whitespace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "filename = 'data/housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataset = pd.read_csv(filename, delim_whitespace=True, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\"> 2. Estadística descriptiva</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de estudiar nuestros datos. En este paso vamos a echar un vistazo a los datos de varias maneras diferentes:\n",
    "* Dimensiones del conjunto de datos.\n",
    "* Visualización de datos.\n",
    "* Resumen estadístico de todos los atributos.\n",
    "* Coorelación de atributos numéricos.\n",
    "* Tipo de atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a>\n",
    "## <font color=\"#004D7F\"> 2.1. Dimensiones del conjunto de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos tener una idea rápida de cuántas instancias (filas) y cuántos atributos (columnas) hay en nuestro conjunto de datos con la propiedad `shape`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shape\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede verse 506 instancias y 14 atributos (incluyendo la clase `MEDV`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a>\n",
    "## <font color=\"#004D7F\"> 2.2. Visualización de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También siempre es una buena idea ver como están representados los datos con la función `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# head\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las primeras 5 filas de los datos y todas las columnas con la misma distribución. Además, podemos confirmar que las escalas de los atributos están por todas partes debido a las diferentes unidades. Podemos beneficiarnos de algunas transformaciones más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section23\"></a>\n",
    "## <font color=\"#004D7F\"> 2.3. Resumen estadístico</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso podemos echar un vistazo a un resumen de cada atributo con la función `describe()`. Esto incluye la media, los valores mínimo y máximo, así como algunos percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# descriptions\n",
    "pd.set_option('display.precision', 1)\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos una mejor idea de cuán diferentes son los atributos. Los valores mínimos y máximos también son las medias que varían mucho. Es probable que obtengamos mejores resultados volviendo a escalar los datos de alguna manera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section24\"></a>\n",
    "## <font color=\"#004D7F\"> 2.4. Tipo de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver el tipo de variable de cada atributo con la propiedad `dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# types\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que todos los atributos son numéricos, en su mayoría valores reales _(float64)_ y algunos han sido interpretados como enteros _(int)_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section25\"></a>\n",
    "## <font color=\"#004D7F\"> 2.5. Correlación entre atributos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya hemos visto es importante ver la correlación entre atributos ya que es preferible tener características indpendientes entre ella y dependientes con la clase. Para elo utilizaremos la función `corr(method='pearson')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# correlation\n",
    "pd.set_option('display.precision', 2)\n",
    "print(dataset.???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es interesante. Podemos ver que muchos de los atributos tienen una fuerte correlación (por ejemplo, $>0.70$ o $<−0.70$). Por ejemplo:\n",
    "* `NOX` y `INDUS` con 0.77.\n",
    "* `DIS` y `INDUS` con -0.71.\n",
    "* `TAX` y `INDUS` con 0.72.\n",
    "* `AGE` y `NOX` con 0.73.\n",
    "* `DIS` y `NOX` con -0.78.\n",
    "También parece que `LSTAT` tiene una buena correlación negativa con la variable de salida `MEDV` con un valor de -0.74."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section26\"></a>\n",
    "## <font color=\"#004D7F\"> 2.6.Valores NaN</font>\n",
    "Es importante también verificar que no tenemos valores NaN en nuestro dataset. En nuestro caso podemos observar que no tenemos ningún valor NaN en las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la columna 'MEDV'\n",
    "boston_data = dataset.drop('MEDV', axis=1)\n",
    "boston_target = dataset['MEDV']\n",
    "\n",
    "# Después comprobamos los NaN's de nuestros datos, esto podemos hacerlo con Numpy.\n",
    "print(np.sum(np.isnan(boston_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que no tenemos ninguń valor perdido en nuestro dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\"> 3. Visualización del conjunto de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos una idea básica sobre los datos. Necesitamos extender eso con algunas visualizaciones. Vamos a ver dos tipos de gráficos de visualización de datos:\n",
    "* Gráficos univariados para comprender mejor cada atributo.\n",
    "* Gráficos multivariados para comprender mejor las relaciones entre los atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a>\n",
    "## <font color=\"#004D7F\"> 3.1. Gráficos Univariados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con algunas gráficas univariadas, es decir, gráficas de cada variable individual. Es útil con la visualización tener una forma de referirse solo a los atributos de entrada y, por otro lado, solo a los atributos de salida. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section311\"></a>\n",
    "### <font color=\"#004D7F\"> Boxplots</font>\n",
    "Dado que las variables de entrada son numéricas, podemos crear Gráficas Boxplots de cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# box and whisker plots - Matplotlib\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "ax = fig.gca()\n",
    "dataset.plot(ax=ax, kind= 'box', subplots=True, layout=(4,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto ayuda a señalar el sesgo en muchas distribuciones tanto que los datos se ven como valores atípicos (por ejemplo, más allá del bigote de los gráficos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section311\"></a>\n",
    "### <font color=\"#004D7F\"> Histograma</font>\n",
    "También podemos crear un histograma de cada variable de entrada para tener una idea de la distribución. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# histograms - Matplotlib\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "ax = fig.gca()\n",
    "dataset.hist(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que algunos atributos pueden tener una distribución exponencial, como `CRIM`, `ZN`, `AGE` y `B`. Podemos ver que otros pueden tener una distribución bimodal como `RAD` y `TAX`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section311\"></a>\n",
    "### <font color=\"#004D7F\"> Diagrama de densidad</font>\n",
    "Esto es útil, puede ver que muchos de los atributos tienen una distribución sesgada. Una transformación de potencia como una transformación de Box-Cox que puede corregir el sesgo en las distribuciones podría ser útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# density\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "ax = fig.gca()\n",
    "dataset.plot(ax=ax, kind='density', subplots=True, layout=(4,4), sharex=False, legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto quizás agrega más evidencia a nuestra sospecha sobre posibles distribuciones exponenciales y bimodales. También parece que `NOX`, `RM` y `LSTAT` pueden tener distribuciones gaussianas sesgadas, lo que podría ser útil más adelante con las transformaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a>\n",
    "## <font color=\"#004D7F\"> 3.2. Gráficos multivariados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos ver las interacciones entre las variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section321\"></a>\n",
    "### <font color=\"#004D7F\"> Diagramas de dispersión</font>\n",
    "Primero veamos los diagramas de dispersión de todos los pares de atributos y coloreamos los puntos por clase. Además, como los gráficos de dispersión muestran que los puntos para cada clase generalmente están separados, podemos dibujar puntos suspensivos alrededor de ellos.\n",
    "\n",
    "Ahora podemos ver las interacciones entre las variables. Veamos gráficos de dispersión de todos los pares de atributos. Esto puede ser útil para detectar relaciones estructuradas entre variables de entrada. Tenga en cuenta la agrupación diagonal de algunos pares de atributos. Esto sugiere una alta correlación y una relación predecible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scatter plot matrix - Matplotlib\n",
    "plt.rcParams[\"figure.figsize\"] = [15,15]\n",
    "pd.plotting.scatter_matrix(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scatter plot matrix - Seaborn\n",
    "sns.pairplot(dataset);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que algunos de los atributos correlacionados más altos muestran una buena estructura en su relación. No lineal, pero agradables relaciones curvas predecibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section321\"></a>\n",
    "### <font color=\"#004D7F\"> Correlación entre atributos</font>\n",
    "Parece que también hay alguna estructura en el orden de los atributos. El amarilo sugiere una correlación positiva mientras que el azul oscuro una coorelación negativa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation = dataset.corr()\n",
    "plt.figure(figsize=(12,12))\n",
    "ax = sns.heatmap(correlation, vmax=1, square=True, annot = True, cmap = 'viridis')\n",
    "# Esto se ponde debido al bug de Matplotlib 3.1.1 (quitarlo en versiones diferentes)\n",
    "#bottom, top = ax.get_ylim()\n",
    "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "# ----------\n",
    "plt.title('Correlación entre variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como análisis podemos extraer:\n",
    "* Entre las características también podemos ver algo de amarillo oscuro y azul oscuro que sugieren candidatos para la eliminación para mejorar el Accuracy de los modelos.\n",
    "* Entre la característica `CHAS` y la clase `MEDV` podemos ver una correlación casi nula por lo que podría anularse.\n",
    "Algunos de estos análisis lo veremos más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section33\"></a>\n",
    "## <font color=\"#004D7F\"> 3.3. Resumen de ideas</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay mucha estructura en este conjunto de datos. Necesitamos pensar en las transformaciones que podríamos usar más tarde para exponer mejor la estructura, lo que a su vez puede mejorar el Accuracy del modelado. Hasta ahora valdría la pena intentar:\n",
    "* Feature Selection y eliminación de características más correlacionados.\n",
    "* Normalización del conjunto de datos para reducir el efecto de diferentes escalas.\n",
    "* Estandarizar el conjunto de datos para reducir los efectos de diferentes distribuciones.\n",
    "Con mucho tiempo adicional también exploraría la posibilidad de _[Binning](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization.html)_ (discretización) de los datos, también en [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html). Esto a menudo puede mejorar Accuracy de los algoritmos de árbol de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\"> 4. Fase de modelado</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de crear algunos modelos de datos y estimar su Accruacy en datos no etiquetados. Esto es lo que vamos a cubrir en este paso:\n",
    "* Crear conjunto de validación.\n",
    "* Evaluación de línea base.\n",
    "* Evaluar algoritmos: Estandarización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section41\"></a>\n",
    "## <font color=\"#004D7F\"> 4.1. Crear conjunto de validación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una buena idea utilizar un conjunto de validación. Esta es una muestra de los datos que retenemos de nuestro análisis y modelado. Lo usamos justo al final de nuestro proyecto para confirmar el Accuracy de nuestro modelo final. Es una prueba que podemos usar para ver si nos equivocamos y para darnos confianza en nuestras estimaciones de Accuracy en datos no etiquetados. Dividiremos el conjunto de datos cargado en dos, el 80% de los cuales utilizaremos para entrenar nuestros modelos y el 20% como un conjunto de datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tiene datos de entrenamiento en `X_train` e `Y_train` para preparar modelos y conjuntos de `X_validation` e `Y_validation` que podemos usar más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section42\"></a>\n",
    "## <font color=\"#004D7F\"> 4.2. Evaluación de línea base</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No sabemos qué algoritmos funcionarán bien en este conjunto de datos. Podemos intuir que algoritmos de regresión como la LiR y ElasticNet (EN) pueden funcionar bien. También es posible que los CART e incluso SVM funcionen bien, aunque debemos probar. Utilizaremos la validación cruzada 10 _fold_. El conjunto de datos no es demasiado pequeño y esta es una buena configuración de prueba estándar. Evaluaremos algoritmos utilizando la métrica de error cuadrático medio (MSE). MSE dará una idea general de cuán erróneas son todas las predicciones (0 es perfecto)\n",
    "\n",
    "Posteriormente, creamos una línea base de rendimiento en este problema y verifiquemos varios algoritmos diferentes. Seleccionaremos un conjunto de algoritmos diferentes capaces de trabajar en este problema de clasificación. Los seis algoritmos seleccionados incluyen:\n",
    "* __Algoritmos lineales:__ LiR, LASSO y EN.\n",
    "* __Algoritmos no lineales:__ CART, SVM y $k$-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append((???))\n",
    "models.append((???))\n",
    "models.append((???))\n",
    "models.append((???))\n",
    "models.append((???))\n",
    "models.append((???))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los algoritmos usan hiperparámetros predeterminados. Comparemos los algoritmos. Mostraremos la media y la desviación estándar de MSE para cada algoritmo a medida que lo calculemos y recopilemos los resultados para su uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = ???\n",
    "seed = 7\n",
    "scoring = ???\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {cv_results.mean():,.3f} ({cv_results.std():,.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que LiR es el que obtiene el mejor rendimiento seguido muy de cerca de CART. Siempre es aconsejable observar la distribución de las métricas calculados en los _folds_ de validación cruzada. Podemos hacerlo gráficamente usando Boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las diferentes escalas de los datos probablemente están perjudicando la habilidad de todos los algoritmos y quizás más para SVM y $k$-NN. \n",
    "\n",
    "En la siguiente sección veremos cómo ejecutar los mismos algoritmos utilizando una copia estandarizada de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section43\"></a>\n",
    "## <font color=\"#004D7F\"> 4.3. Evaluar modelos: estandarización</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sospechamos que las diferentes distribuciones de los datos en bruto pueden estar afectando negativamente a la habilidad de algunos de los algoritmos. Vamos a evaluar los mismos algoritmos con una copia estandarizada del conjunto de datos. Aquí es donde los datos se transforman de manera que cada atributo tenga un valor medio de cero y una desviación estándar de uno. \n",
    "\n",
    "También debemos evitar la fuga de datos cuando transformamos los datos. Una buena manera de evitar fugas es usar Pipelines que estandaricen los datos y construyan el modelo para cada _fold_ de la validación cruzada. De esa forma podemos obtener una estimación justa de cómo cada modelo con datos estandarizados podría funcionar en datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLiR', Pipeline([('Scaler', StandardScaler()),('LR', LinearRegression())])))\n",
    "pipelines.append((???))\n",
    "pipelines.append((???))\n",
    "pipelines.append((???))\n",
    "pipelines.append((???))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {cv_results.mean():,.3f} ({cv_results.std():,.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar el ejemplo proporciona una lista de errores cuadrados medios. Podemos ver que el escalado tuvo un efecto en $k$-NN, conduciendo el error más bajo que los otros modelos.\n",
    "\n",
    "Echemos un vistazo a la distribución de las puntuaciones en los _fold_ de validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Scaled Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que $k$-NN tiene una distribución estrecha de error y tiene la puntuación más baja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\"> 5. Fase de Optimización</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección investigamos el ajuste de los parámetros para el algoritmo $k$-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section51\"></a>\n",
    "## <font color=\"#004D7F\"> 5.1. Optimización de _k_-NN</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comenzar ajustando el número de vecinos para $k$-NN. El número predeterminado de vecinos es 7. A continuación, probamos todos los valores impares de _k_ del 1 al 21, cubriendo el valor predeterminado de 7. Cada valor de _k_ se evalúa utilizando una validación cruzada 10 veces en el conjunto de datos estandarizado de entrenamiento. Podemos imprimir la configuración que resultó en el más alto Accuracy, así como la Accuracy de todos los valores probados. Ejecutando el ejemplo, vemos los resultados a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune scaled KNN\n",
    "scaler = ???\n",
    "rescaledX = ???\n",
    "k_values = ???\n",
    "param_grid = ???\n",
    "model = ???\n",
    "kfold = ???\n",
    "grid = ???\n",
    "grid_result = ???\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"{param}: {mean:,.2f} ({stdev:,.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la configuración óptima es $k=3$ que nos da, diferencia el mejor MSE con -18.11 (12.88)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section6\"></a>\n",
    "# <font color=\"#004D7F\"> 6. Algoritmos ensamblados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma en que podemos mejorar el rendimiento de los algoritmos en este problema es mediante el uso de modelos ensamblados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section61\"></a>\n",
    "## <font color=\"#004D7F\"> 6.1. Comparar algoritmos ensamblados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección evaluaremos cuatro algoritmos ensamblados diferentes, dos tipo Boosting y dos tipo  Bagging:\n",
    "* Métodos Boosting: AdaBoost (AB) y Gradient Boosting (GBM).\n",
    "* Métodos Bagging: Random Forest (RF) y Extra Trees (ET).\n",
    "\n",
    "Utilizaremos una validación cruzada de 10 y un Pipeline que estandarizan los datos de entrenamiento para cada _fold_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensembles\n",
    "ensembles = []\n",
    "ensembles.append(('ScaledAB', Pipeline([('Scaler', StandardScaler()),('AB', AdaBoostRegressor())])))\n",
    "???\n",
    "???\n",
    "???\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {cv_results.mean():,.2f} ({cv_results.std():,.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar el ejemplo calcula el error cuadrático medio para cada método utilizando los parámetros predeterminados. Podemos ver que generalmente estamos obteniendo mejores puntajes que nuestros algoritmos lineales y no lineales en secciones anteriores.\n",
    "\n",
    "También podemos trazar la distribución de puntajes en los _fold_ de validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Ensemble Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que GBM tiene una mejor puntuación media, también parece que ET tiene una distribución similar y tal vez una mejor puntuación media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section62\"></a>\n",
    "## <font color=\"#004D7F\"> 6.2. Fase de optimización GBM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número predeterminado de etapas de refuerzo para realizar (`n_estimators`) es 100. Este es un buen parámetro candidato de GBM para optimizar. A menudo, cuanto mayor sea el número de etapas de impulso, mejor será el rendimiento, pero mayor será el tiempo de entrenamiento. En esta sección, veremos cómo ajustar el número de etapas para aumentar el gradiente. \n",
    "\n",
    "A continuación, definimos una `GridSearchCV` con valores de estimadores de 50 a 400 en incrementos de 50. Cada configuración se evalúa mediante una validación cruzada de 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune scaled GBM\n",
    "scaler = ???\n",
    "rescaledX = ???\n",
    "param_grid = ???\n",
    "model = ???\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "grid = ???\n",
    "grid_result = grid.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como antes, podemos resumir la mejor configuración y tener una idea de cómo cambió el rendimiento con cada configuración diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"{param}: {mean:,.3f} ({stdev:,.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la mejor configuración fue `n_estimators = 400`, lo que resultó en un error cuadrático medio de -9.380, casi 1 unidad mejor que el método no optimizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section7\"></a>\n",
    "# <font color=\"#004D7F\"> 7. Fase de Forecasting</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección finalizaremos el modelo de aumento de gradiente y lo evaluaremos en nuestro conjunto de datos de validación. Primero necesitamos preparar el modelo y entrenarlo en todo el conjunto de datos de entrenamiento. Esto incluye estandarizar el conjunto de datos de entrenamiento antes del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = GradientBoostingRegressor(random_state=seed, n_estimators=400)\n",
    "model.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego podemos escalar las entradas para el conjunto de datos de validación y generar predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the validation dataset\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(mean_squared_error(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el error cuadrático medio estimado es 11.8, cercano a nuestra estimación de -9.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
