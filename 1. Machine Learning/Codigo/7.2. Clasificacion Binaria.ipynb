{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=6>Módulo 7. Proyectos de Machine Learning</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=5>2. Proyecto de clasificación binaria</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Machine Learning con Python</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "<a id=\"indice\"></a>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "    * [1.1. Importar librerías](#section11)\n",
    "    * [2.1. Cargar el dataset](#section12)\n",
    "* [2. Estadística descriptiva](#section2)\n",
    "    * [2.1. Dimensiones del dataset](#section21)\n",
    "    * [2.2. Visualización de datos](#section22)\n",
    "    * [2.3. Resumen estadístico](#section23)\n",
    "    * [2.4. Distribución de clase](#section24)\n",
    "    * [2.5. Tipo de datos](#section25)\n",
    "* [3. Visualización del dataset](#section3)\n",
    "    * [3.1. Gráficos Univariado](#section31)\n",
    "    * [3.2. Gráficos multivariados](#section32)\n",
    "* [4. Fase de modelado](#section4)\n",
    "    * [4.1. Crear conjunto de validación](#section41)\n",
    "    * [4.2. Evaluación de línea base](#section42)\n",
    "    * [4.3. Evaluar modelos: estandarización](#section43)\n",
    "* [5. Fase de Optimización](#section5)\n",
    "    * [5.1. Optimización de k-NN](#section51)\n",
    "    * [5.2. Optimización de SVM](#section52)\n",
    "* [6. Agoritmos ensamblados](#section6)\n",
    "* [7. Fase de forecasting](#section7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Introducción</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El enfoque de este proyecto será el conjunto de datos [Sonar Mines vs Rocks](https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)). El problema es predecir objetos de metal o roca a partir de los datos de retorno de la sonda. Cada patrón es un conjunto de 60 números en el rango de 0.0 a 1.0. Cada número representa la energía dentro de una banda de frecuencia particular, integrada durante un cierto período de tiempo. La etiqueta asociada con cada registro contiene la letra \"R\" si el objeto es una roca y \"M\" si es una mina (cilindro de metal). Los números en las etiquetas están en orden creciente de ángulo de aspecto, pero no codifican el ángulo directamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "## <font color=\"#004D7F\"> 1.1. Importar librerías</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, importemos todos los módulos, funciones y objetos que vamos a utilizar en este tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Project: Sonar rocks or mines\n",
    "\n",
    "# Load libraries\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Load sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 1.2. Cargar el dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos de Sonar se puede descargar desde el repositorio de UCI Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "filename = 'data/sonar.all-data.csv'\n",
    "dataset = pd.read_csv(filename, header=None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\"> 2. Estadística descriptiva</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de estudiar nuestros datos. En este paso vamos a echar un vistazo a los datos de varias maneras diferentes:\n",
    "* Dimensiones del conjunto de datos.\n",
    "* Visualización de datos.\n",
    "* Resumen estadístico de todos los atributos.\n",
    "* Desglosar las instancias en cada clase.\n",
    "* Tipo de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a>\n",
    "## <font color=\"#004D7F\"> 2.1. Dimensiones del conjunto de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos tener una idea rápida de cuántas instancias (filas) y cuántos atributos (columnas) hay en nuestro conjunto de datos con la propiedad `shape`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shape\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede verse 208 instancias y 61 atributos (incluyendo la clase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a>\n",
    "## <font color=\"#004D7F\"> 2.2. Visualización de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También siempre es una buena idea ver como están representados los datos con la función `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# head\n",
    "pd.set_option('display.width', 100)\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las primeras 5 filas de los datos y todas las columnas con la misma distribución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section23\"></a>\n",
    "## <font color=\"#004D7F\"> 2.3. Resumen estadístico</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso podemos echar un vistazo a un resumen de cada atributo con la función `describe()`. Esto incluye la media, los valores mínimo y máximo, así como algunos percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# descriptions\n",
    "pd.set_option('display.precision', 3)\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section24\"></a>\n",
    "## <font color=\"#004D7F\"> 2.4. Distribución de clase</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, veamos ahora la cantidad de instancias (filas) que pertenecen a cada clase. Podemos ver esto como una cuenta absoluta y como un porcentaje con la función `groupby('class').size()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# class distribution\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que cada clase se encuentra más o menos balanceada entre las dos clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section25\"></a>\n",
    "## <font color=\"#004D7F\"> 2.5. Tipo de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, veamos el tipo de variable de cada atributo con la propiedad `dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# types\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que todos los atributos son numéricos (flotantes) y que el valor de la clase se ha leído como un objeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section311\"></a>\n",
    "### <font color=\"#004D7F\"> Valores NaN</font>\n",
    "Es importante también verificar que no tenemos valores NaN en nuestro dataset. En nuestro caso podemos observar que no tenemos ningún valor NaN en las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobamos si existen NaN\n",
    "print(dataset.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section311\"></a>\n",
    "### <font color=\"#004D7F\">Características y Target</font>\n",
    "Por último, tenemos que separa las variables características del target de manera que tendremos dos dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las características\n",
    "sonar_data = dataset.drop(dataset.columns[60], axis=1)\n",
    "# Seleccionamos el target\n",
    "sonar_target = dataset.iloc[:, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sonar_target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\"> 3. Visualización del conjunto de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos una idea básica sobre los datos. Necesitamos extender eso con algunas visualizaciones. Vamos a ver dos tipos de gráficos de visualización de datos:\n",
    "* Gráficos univariados para comprender mejor cada atributo.\n",
    "* Gráficos multivariados para comprender mejor las relaciones entre los atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a>\n",
    "## <font color=\"#004D7F\"> 3.1. Gráficos Univariados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con algunas gráficas univariadas, es decir, gráficas de cada variable individual. Es útil con la visualización tener una forma de referirse solo a los atributos de entrada y, por otro lado, solo a los atributos de salida. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section311\"></a>\n",
    "### <font color=\"#004D7F\"> Boxplots</font>\n",
    "Dado que las variables de entrada son numéricas, podemos crear Gráficas Boxplots de cada uno. Podemos ver que los atributos tienen diferenciales bastante diferentes. Dado que las escalas son las mismas, puede sugerir algún beneficio al estandarizar los datos para el modelado para alinear todos los medios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# box and whisker plots - Matplotlib\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "ax = fig.gca()\n",
    "(dataset.plot(ax=ax, kind= 'box', subplots=True, layout=(9,7))\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "\n",
    "Importante: Hay un bug en Matplotlib y es por eso que hay que poner el `rename`. [Referencia 1](https://stackoverflow.com/questions/53385592/seaborn-issue-with-catplot) y [Referencia 2](https://stackoverflow.com/questions/59199393/i-get-an-error-when-i-use-boxplot-from-pandas-with-subplots)\n",
    "\n",
    "Si no sale sin `rename` utiliza este código:\n",
    "```python\n",
    "    (dataset.rename(columns=lambda x: str(x))\n",
    "        .plot(ax=ax, kind= 'box', subplots=True, layout=(9,7))\n",
    "    )  \n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section311\"></a>\n",
    "### <font color=\"#004D7F\"> Histograma</font>\n",
    "También podemos crear un histograma de cada variable de entrada para tener una idea de la distribución. Parece que quizás dos de las variables de entrada tienen una distribución gaussiana. Es útil tener en cuenta que podemos usar algoritmos que pueden explotar esta suposición. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# histograms - Matplotlib\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "ax = fig.gca()\n",
    "dataset.hist(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section311\"></a>\n",
    "### <font color=\"#004D7F\"> Diagrama de densidad</font>\n",
    "Esto es útil, puede ver que muchos de los atributos tienen una distribución sesgada. Una transformación de potencia como una transformación de Box-Cox que puede corregir el sesgo en las distribuciones podría ser útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density\n",
    "fig = plt.figure(figsize = (20,20))\n",
    "ax = fig.gca()\n",
    "dataset.plot(ax=ax, kind='density', subplots=True, layout=(8,8), sharex=False, legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot.density(figsize=(6, 60), subplots=True, yticks=[])\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a>\n",
    "## <font color=\"#004D7F\"> 3.2. Gráficos multivariados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos ver las interacciones entre las variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section321\"></a>\n",
    "### <font color=\"#004D7F\"> Correlación entre atributos</font>\n",
    "Parece que también hay alguna estructura en el orden de los atributos. El amarilo alrededor de la diagonal sugiere que los atributos que están uno al lado del otro generalmente están más correlacionados entre sí. Los parches azules también sugieren una correlación negativa moderada, los atributos adicionales están lejos unos de otros en el orden. Esto tiene sentido si el orden de los atributos se refiere al ángulo de los sensores para el sonido del sonar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(sonar_data.corr(), vmin=-1, vmax=1, interpolation='none')\n",
    "fig.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation = sonar_data.corr()\n",
    "plt.figure(figsize=(50,50))\n",
    "ax = sns.heatmap(correlation, vmax=1, square=True, annot = True, cmap = 'viridis')\n",
    "# Esto se ponde debido al bug de Matplotlib 3.1.1 (quitarlo en versiones diferentes)\n",
    "#bottom, top = ax.get_ylim()\n",
    "#ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "# ----------\n",
    "plt.title('Correlación entre variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\"> 4. Fase de modelado</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de crear algunos modelos de datos y estimar su Accruacy en datos no etiquetados. Esto es lo que vamos a cubrir en este paso:\n",
    "* Crear conjunto de validación.\n",
    "* Evaluación de línea base.\n",
    "* Evaluar algoritmos: Estandarización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section41\"></a>\n",
    "## <font color=\"#004D7F\"> 4.1. Crear conjunto de validación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una buena idea utilizar un conjunto de validación. Esta es una muestra de los datos que retenemos de nuestro análisis y modelado. Lo usamos justo al final de nuestro proyecto para confirmar el Accuracy de nuestro modelo final. Es una prueba que podemos usar para ver si nos equivocamos y para darnos confianza en nuestras estimaciones de Accuracy en datos no etiquetados. Dividiremos el conjunto de datos cargado en dos, el 80% de los cuales utilizaremos para entrenar nuestros modelos y el 20% como un conjunto de datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = ???\n",
    "Y = ???\n",
    "validation_size = ???\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tiene datos de entrenamiento en `X_train` e `Y_train` para preparar modelos y conjuntos de `X_validation` e `Y_validation` que podemos usar más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section42\"></a>\n",
    "## <font color=\"#004D7F\"> 4.2. Evaluación de línea base</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No sabemos qué algoritmos funcionarán bien en este conjunto de datos. Podemos intuir que algoritmos basados en la distancia como $k$-NN y SVM pueden funcionar bien. Utilizaremos la validación cruzada 10 veces. El conjunto de datos no es demasiado pequeño y esta es una buena configuración estándar. Evaluaremos algoritmos utilizando la métrica Accuracy ya que las clases estaban balanceadas. Esta es una métrica general que dará una idea rápida de cuán correcto es un modelo dado. Más útil en problemas de clasificación binaria como este.\n",
    "\n",
    "Posteriormente, creamos una línea base de rendimiento en este problema y verifiquemos varios algoritmos diferentes. Seleccionaremos un conjunto de algoritmos diferentes capaces de trabajar en este problema de clasificación. Los seis algoritmos seleccionados incluyen:\n",
    "* __Algoritmos lineales:__ LoR y LDA.\n",
    "* __Algoritmos no lineales:__ CART, SVM, NB y $k$-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append((???))\n",
    "models.append((???))\n",
    "models.append((???))\n",
    "models.append((???))\n",
    "models.append((???))\n",
    "models.append((???))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los algoritmos usan hiperparámetros predeterminados. Comparemos los algoritmos. Mostraremos la media y la desviación estándar de Accuracy para cada algoritmo a medida que lo calculemos y recopilemos los resultados para su uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = ???\n",
    "seed = 7\n",
    "scoring = ???\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = ???\n",
    "    cv_results = ???\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {cv_results.mean()*100.0:,.2f}% ({cv_results.std()*100.0:,.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son solo valores medios de Accuracy. Siempre es aconsejable observar la distribución de los valores de Accuracy calculados en los _folds_ de validación cruzada. Podemos hacerlo gráficamente usando Boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados muestran una distribución estrecha de $k$-NN y SVM que es alentadora, lo que sugiere una baja variación. NB, además de tener un resultado malo tiene un varianza muy grande por lo que lo hace un algoritmo muy inconsisten para neustros datos. Sin embargo, $k$-NN tiene un comportamiento en cada _fold_ muy regular, lo que hace que sea un algoritmo óptimo.\n",
    "\n",
    "Es posible que la distribución variada de los atributos tenga un efecto en el Accuracy de algoritmos como SVM. En la siguiente sección, repetiremos esta comprobación realizando una estandarización del conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section43\"></a>\n",
    "## <font color=\"#004D7F\"> 4.3. Evaluar modelos: estandarización</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sospechamos que las diferentes distribuciones de los datos en bruto pueden estar afectando negativamente a la habilidad de algunos de los algoritmos. Vamos a evaluar los mismos algoritmos con una copia estandarizada del conjunto de datos. Aquí es donde los datos se transforman de manera que cada atributo tenga un valor medio de cero y una desviación estándar de uno. \n",
    "\n",
    "También debemos evitar la fuga de datos cuando transformamos los datos. Una buena manera de evitar fugas es usar Pipelines que estandaricen los datos y construyan el modelo para cada _fold_ de la validación cruzada. De esa forma podemos obtener una estimación justa de cómo cada modelo con datos estandarizados podría funcionar en datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLoR', Pipeline([('Scaler', StandardScaler()),('LR', LogisticRegression())])))\n",
    "???\n",
    "???\n",
    "???\n",
    "???\n",
    "???\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {cv_results.mean()*100.0:,.2f}% ({cv_results.std()*100.0:,.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar el ejemplo proporciona los resultados enumerados a continuación. Podemos ver que $k$-NN todavía está bien, incluso mejor que antes. También podemos ver que la estandarización de los datos ha elevado la habilidad de SVM para ser el algoritmo con mejor desempeño (aunque con más varianza que $k$-NN) probado hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Scaled Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados sugieren profundizar en los algoritmos SVM y $k$-NN. Es muy probable que una configuración más allá de la predeterminada pueda generar modelos con mejor desempeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\"> 5. Fase de Optimización</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección investigamos el ajuste de los parámetros para dos algoritmos que muestran mejores resultados, estos son: $k$-NN y SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section51\"></a>\n",
    "## <font color=\"#004D7F\"> 5.1. Optimización de _k_-NN</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comenzar ajustando el número de vecinos para $k$-NN. El número predeterminado de vecinos es 7. A continuación, probamos todos los valores impares de _k_ del 1 al 21, cubriendo el valor predeterminado de 7. Cada valor de _k_ se evalúa utilizando una validación cruzada 10 veces en el conjunto de datos estandarizado de entrenamiento. Podemos imprimir la configuración que resultó en el más alto Accuracy, así como la Accuracy de todos los valores probados. Ejecutando el ejemplo, vemos los resultados a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tune scaled KNN\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "neighbors = [1,3,5,7,9,11,13,15,17,19,21]\n",
    "param_grid = dict(n_neighbors=neighbors)\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"{param}: {mean*100.0:,.2f}% ({stdev*100.0:,.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la configuración óptima es $k=1$. Esto es interesante ya que el algoritmo hará predicciones utilizando la instancia más similar en el conjunto de datos de entrenamiento solo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section52\"></a>\n",
    "## <font color=\"#004D7F\"> 5.2. Optimización de SVM</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ajustar dos parámetros clave del algoritmo SVM, el valor de _C_ (cuánto relajar el margen) y el tipo de _kernel_. El valor predeterminado para SVM (la clase SVC) es usar el _kernel_ de la función de base radial _(RBF)_ con un valor de _C_ establecido en 1.0. Al igual que con $k$-NN, realizaremos un `GridSearchCV` utilizando una validación cruzada de 10 con una copia estandarizada del conjunto de datos de entrenamiento. Intentaremos una serie de tipos de _kernel_ más simples y valores de _C_ con menos sesgo y más sesgo (menor que y más de 1.0 respectivamente). \n",
    "\n",
    "Ejecutar el ejemplo imprime la mejor configuración, la precisión y las precisiones para todas las combinaciones de configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tune scaled SVM\n",
    "scaler = ???\n",
    "rescaledX = ???\n",
    "c_values = ???\n",
    "kernel_values = ???\n",
    "param_grid = ???\n",
    "model = ???\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "grid = ???\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"{param}: {mean*100.0:,.2f}% ({stdev*100.0:,.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la configuración más precisa fue SVM con un _kernel RBF_ y un valor _C_ de 2.0. La precisión del 86.7470% es aparentemente mejor de lo que $k$-NN podría lograr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section6\"></a>\n",
    "# <font color=\"#004D7F\"> 6. Algoritmos ensamblados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma en que podemos mejorar el rendimiento de los algoritmos en este problema es mediante el uso de modelos ensamblados. En esta sección evaluaremos cuatro algoritmos ensamblados diferentes, dos tipo Boosting y dos tipo  Bagging:\n",
    "* Métodos Boosting: AdaBoost (AB) y Gradient Boosting (GBM).\n",
    "* Métodos Bagging: Random Forest (RF) y Extra Trees (ET).\n",
    "\n",
    "Utilizaresmo una validación cruzada de 10. No se utiliza la estandarización de datos en este caso porque los cuatro algoritmos de conjunto se basan en árboles de decisión que son menos sensibles a las distribuciones de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensembles\n",
    "ensembles = []\n",
    "ensembles.append(('AB', AdaBoostClassifier()))\n",
    "ensembles.append((???))\n",
    "ensembles.append((???))\n",
    "ensembles.append((???))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {mean*100.0:,.2f}% ({stdev*100.0:,.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que ambas técnicas proporcionan puntajes de Accuracy bajos (por debajo de 80%) con configuraciones predeterminadas. Podemos trazar la distribución de puntajes de Accruacy en los _folds_ de validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Ensemble Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados sugieren que GBM puede ser digno de un estudio adicional, con una media fuerte y una extensión que se inclina hacia el 90% de Accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section7\"></a>\n",
    "# <font color=\"#004D7F\"> 7. Fase de Forecasting</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El SVM mostró el mejor resultado como un modelo estable y de baja complejidad para este problema. En esta sección finalizaremos el modelo entrenándolo en todo el conjunto de datos de entrenamiento y haremos predicciones para el conjunto de datos de validación para confirmar nuestros hallazgos. \n",
    "\n",
    "Una parte de los resultados fue que SVM funciona mejor cuando el conjunto de datos está estandarizado, de modo que todos los atributos tienen un valor medio de cero y una desviación estándar de uno. Podemos calcular esto a partir del conjunto de datos de entrenamiento completo y aplicar la misma transformación a los atributos de entrada del conjunto de datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize Model\n",
    "# prepare the model\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = SVC(C=1.5)\n",
    "model.fit(rescaledX, Y_train)\n",
    "# estimate accuracy on validation dataset\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que alcanzamos una precisión de casi el 86% en el conjunto de datos de validación extendido. Una puntuación que coincide estrechamente con nuestras expectativas estimadas anteriormente durante el ajuste de SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
