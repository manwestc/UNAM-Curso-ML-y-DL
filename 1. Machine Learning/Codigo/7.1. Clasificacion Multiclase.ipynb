{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=6>Módulo 7. Proyectos de Machine Learning</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=5>1. Proyecto de clasificación multiclase</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Machine Learning con Python</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "<a id=\"indice\"></a>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "    * [1.1. Importar librerías](#section11)\n",
    "    * [1.2. Cargar el dataset](#section12)\n",
    "* [2. Estadística descriptiva](#section2)\n",
    "    * [2.1. Dimensiones del dataset](#section21)\n",
    "    * [2.2. Visualización de datos](#section22)\n",
    "    * [2.3. Resumen estadístico](#section23)\n",
    "    * [2.4. Distribución de clase](#section24)\n",
    "* [3. Visualización del dataset](#section3)\n",
    "    * [3.1. Gráficos Univariado](#section31)\n",
    "    * [3.2. Gráficos multivariados](#section32)\n",
    "* [4. Fase de modelado](#section4)\n",
    "    * [4.1. Crear conjunto de validación](#section41)\n",
    "    * [4.2. Validación cruzada](#section42)\n",
    "    * [4.3. Evaluar modelos](#section43)\n",
    "    * [4.4. Seleccionar el mejor modelo](#section44)\n",
    "* [5. Fase de Forecasting](#section5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Introducción</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor proyecto, de tamaño pequeño, para comenzar con machine learning es el conjunto de datos de [Iris](https://archive.ics.uci.edu/ml/datasets/iris). Este es un buen conjunto de datos para un primer proyecto porque se entiende muy bien. \n",
    "\n",
    "Recordemos algunas características principales:\n",
    "   * Los atributos son numéricos, por lo que debemos averiguar cómo cargar y manejar los datos.\n",
    "   * Es un problema de clasificación, que nos permite practicar con quizás un tipo más fácil de algoritmo de aprendizaje supervisado.\n",
    "   * Es un problema de clasificación multiclase (multi-nominal) que puede requerir un manejo especializado.\n",
    "   * Solo tiene 4 atributos y 150 filas, lo que significa que es pequeño y cabe fácilmente en la memoria principal.\n",
    "   * Todos los atributos numéricos están en las mismas unidades y la misma escala no requiere ningún escalado especial o transformaciones para comenzar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "## <font color=\"#004D7F\"> 1.1. Importar librerías</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, importemos todos los módulos, funciones y objetos que vamos a utilizar en este tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 1.2. Cargar el dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos de Iris se puede descargar desde el repositorio de UCI Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "filename = 'data/iris.data.csv'\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = pd.read_csv(filename, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\"> 2. Estadística descriptiva</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de estudiar nuestros datos. En este paso vamos a echar un vistazo a los datos de varias maneras diferentes:\n",
    "   * Dimensiones del conjunto de datos.\n",
    "   * Visualización de datos.\n",
    "   * Resumen estadístico de todos los atributos.\n",
    "   * Desglosar las instancias en cada clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a>\n",
    "## <font color=\"#004D7F\"> 2.1. Dimensiones del conjunto de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos tener una idea rápida de cuántas instancias (filas) y cuántos atributos (columnas) hay en nuestro conjunto de datos con la propiedad `shape`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shape\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede verse 150 instancias y 5 atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a>\n",
    "## <font color=\"#004D7F\"> 2.2. Visualización de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También siempre es una buena idea ver como están representados los datos con la función `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# head\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las primeras 5 filas de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section23\"></a>\n",
    "## <font color=\"#004D7F\"> 2.3. Resumen estadístico</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso podemos echar un vistazo a un resumen de cada atributo con la función `describe()`. Esto incluye la media, los valores mínimo y máximo, así como algunos percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# descriptions\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que todos los valores numéricos tienen la misma escala (centímetros) y similar rangos $[0,8]$ centímetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section24\"></a>\n",
    "## <font color=\"#004D7F\"> 2.4. Distribución de clase</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, veamos ahora la cantidad de instancias (filas) que pertenecen a cada clase. Podemos ver esto como una cuenta absoluta y como un porcentaje con la función `groupby('class').size()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# class distribution\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que cada clase tiene el mismo número de instancias (50 ó el 33% del conjunto de datos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\"> 3. Visualización del conjunto de datos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos una idea básica sobre los datos. Necesitamos extender eso con algunas visualizaciones. Vamos a ver dos tipos de gráficos de visualización de datos:\n",
    "* Gráficos univariados para comprender mejor cada atributo.\n",
    "* Gráficos multivariados para comprender mejor las relaciones entre los atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a>\n",
    "## <font color=\"#004D7F\"> 3.1. Gráficos Univariados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con algunas gráficas univariadas, es decir, gráficas de cada variable individual. Es útil con la visualización tener una forma de referirse solo a los atributos de entrada y, por otro lado, solo a los atributos de salida. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section311\"></a>\n",
    "### <font color=\"#004D7F\"> Boxplots</font>\n",
    "Dado que las variables de entrada son numéricas, podemos crear Gráficas Boxplots de cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box and whisker plots \n",
    "f, axes = plt.subplots(2, 2, figsize=(10, 7))\n",
    "sns.boxplot(dataset[\"sepal-length\"], ax=axes[0, 0])\n",
    "sns.boxplot(dataset[\"sepal-width\"], ax=axes[0, 1])\n",
    "sns.boxplot(dataset[\"petal-length\"], ax=axes[1, 0])\n",
    "sns.boxplot(dataset[\"petal-width\"], ax=axes[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# box and whisker plots - Matplotlib\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.gca()\n",
    "dataset.plot(ax=ax, kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section311\"></a>\n",
    "### <font color=\"#004D7F\"> Histograma</font>\n",
    "También podemos crear un histograma de cada variable de entrada para tener una idea de la distribución. Parece que quizás dos de las variables de entrada tienen una distribución gaussiana. Es útil tener en cuenta que podemos usar algoritmos que pueden explotar esta suposición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms - Seaborn\n",
    "f, axes = plt.subplots(2, 2, figsize=(10,5))\n",
    "sns.distplot(dataset[\"sepal-length\"], ax=axes[0, 0])\n",
    "sns.distplot(dataset[\"sepal-width\"], ax=axes[0, 1])\n",
    "sns.distplot(dataset[\"petal-length\"], ax=axes[1, 0])\n",
    "sns.distplot(dataset[\"petal-width\"], ax=axes[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms - Matplotlib\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "ax = fig.gca()\n",
    "dataset.hist(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section32\"></a>\n",
    "## <font color=\"#004D7F\"> 3.2. Gráficos multivariados</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos ver las interacciones entre las variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section321\"></a>\n",
    "### <font color=\"#004D7F\"> Diagramas de dispersión</font>\n",
    "Primero veamos los diagramas de dispersión de todos los pares de atributos y coloreamos los puntos por clase. Además, como los gráficos de dispersión muestran que los puntos para cada clase generalmente están separados, podemos dibujar puntos suspensivos alrededor de ellos.\n",
    "\n",
    "Ahora podemos ver las interacciones entre las variables. Veamos gráficos de dispersión de todos los pares de atributos. Esto puede ser útil para detectar relaciones estructuradas entre variables de entrada.\n",
    "Tenga en cuenta la agrupación diagonal de algunos pares de atributos. Esto sugiere una alta correlación y una relación predecible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot matrix - Seaborn\n",
    "sns.pairplot(dataset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scatter plot matrix - Matplotlib\n",
    "plt.rcParams[\"figure.figsize\"] = [12,8]\n",
    "pd.plotting.scatter_matrix(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\"> 4. Fase de modelado</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de crear algunos modelos de datos y estimar su Accruacy en datos no etiquetados. Esto es lo que vamos a cubrir en este paso:\n",
    "* Crear conjunto de validación.\n",
    "* Configurar una validación cruzada de 10-fold.\n",
    "* Construir 5 modelos diferentes y evaluar el rendimiento de cada uno de ellos en este conjunto de datos.\n",
    "* Seleccionar el mejor modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section41\"></a>\n",
    "## <font color=\"#004D7F\"> 4.1. Crear conjunto de validación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos saber si el modelo que vayamos a crear será bueno. Más adelante, usaremos métodos estadísticos para estimar el Accuracy de los modelos que creamos en datos no etiquetados. También queremos una estimación más concreta del Accuracy del mejor modelo en datos no etiquetados mediante su evaluación en datos reales invisibles. Es decir, vamos a retener algunos datos que los algoritmos no podrán ver y usaremos estos datos para obtener una segunda idea independiente de qué tan exacto podría ser el mejor modelo. Dividiremos el conjunto de datos cargado en dos, el 80% de los cuales utilizaremos para entrenar nuestros modelos y el 20% como un conjunto de datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = ???\n",
    "Y = ???\n",
    "validation_size = ???\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tiene datos de entrenamiento en `X_train` e `Y_train` para preparar modelos y conjuntos de `X_validation` e `Y_validation` que podemos usar más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section42\"></a>\n",
    "## <font color=\"#004D7F\"> 4.2. Validación cruzada</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos la validación cruzada 10 veces para estimar el Accuracy. Esto dividirá nuestro conjunto de datos en 10 partes, entrenará en 9 y probará en 1 y repetirá para todas las combinaciones de divisiones de train/test. Estamos utilizando la métrica de Accuracy para evaluar modelos. Esta es una proporción del número de instancias correctamente predichas dividido por el número total de instancias en el conjunto de datos multiplicado por 100 para dar un porcentaje (por ejemplo, 95% de Accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section43\"></a>\n",
    "## <font color=\"#004D7F\"> 4.3. Evaluar modelos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No sabemos qué algoritmos serían buenos para este problema ni qué configuraciones utilizar. A partir de los gráficos, obtenemos una idea de que algunas de las clases son parcialmente separables linealmente en algunas dimensiones, por lo que en general esperamos buenos resultados. Vamos a evaluar 6 algoritmos diferentes:\n",
    "* Logistic Regression (LoR)\n",
    "* Linear Discriminant Analysis (LDA).\n",
    "* Classification and Regression Trees (CART).\n",
    "* $k$-Nearest Neighbors ($k$-NN).\n",
    "* Support Vector Machines (SVM).\n",
    "* Gaussian Navie Bayes (NB).\n",
    "\n",
    "Esta es una buena mezcla de métodos lineales simples (LoR, LDA), no lineales (CART, $k$-NN, SVM, NB). Reajustamos el número aleatorio de \\textit{seed} antes de cada ejecución para asegurarnos de que la evaluación de cada algoritmo se realice utilizando exactamente las mismas divisiones de datos. Asegura que los resultados son directamente comparables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "models = []\n",
    "models.append(('LoR', LogisticRegression()))\n",
    "???\n",
    "???\n",
    "???\n",
    "???\n",
    "???\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "seed=3\n",
    "for name, model in models:\n",
    "    kfold = ???\n",
    "    cv_results = ???\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f\"{name}: {cv_results.mean()*100.0:,.2f}% ({cv_results.std()*100.0:,.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section44\"></a>\n",
    "## <font color=\"#004D7F\"> 4.4. Seleccionar el mejor modelo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos 6 modelos y estimaciones de Accruacy para cada uno de ellos. Necesitamos comparar los modelos entre sí y seleccionar los más precisos. Podemos informar sobre el Accuracy de cada modelo creando primero una lista de los modelos, reuniendo estadísticas de remuestreo y utilizando la función de resumen en el resultado.\n",
    "\n",
    "Podemos ver que LoR, $k$-NN y SVM tienen el mejor Accuracy. También podemos crear una gráfica de los resultados de la evaluación del modelo y comparar la dispersión y el Accuracy medio de cada modelo. Hay una población de medidas de Accuracy para cada algoritmo porque cada algoritmo se evaluó 10 veces (validación cruzada 10 veces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\"> 5. Fase de Forecasting</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a seleccionar el algoritmo $k$-NN como el modelo más preciso. Ahora queremos tener una idea del Accuracy del modelo en nuestro conjunto de validación. Esto nos dará una verificación final independiente sobre el Accuracy del mejor modelo. Es valioso mantener un conjunto de validación en caso de que haya cometido un error durante el entrenamiento, como el ajuste excesivo del conjunto de entrenamiento o una fuga de datos. Ambos darán como resultado un resultado demasiado optimista. Podemos ejecutar el modelo $k$-NN directamente en el conjunto de validación y resumir los resultados en una matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
